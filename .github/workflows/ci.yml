name: Backend Quality CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/ci.yml'

env:
  PYTHON_VERSION: '3.13'
  WORKING_DIR: backend

jobs:
  # Reusable job template for all quality checks
  quality-check:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        include:
          - job: test
            needs_env: true
            make_target: ci-test
            summary_script: extract_coverage_score.py
            summary_file: coverage_summary.txt
            summary_format: "Coverage: {score}%"
          - job: coverage
            needs_env: true
            make_target: ci-test
            summary_script: extract_coverage_score.py
            summary_file: coverage_summary.txt
            summary_format: "Coverage: {score}%"
          - job: security
            needs_env: false
            make_target: ci-security
            summary_script: extract_security_score.py
            summary_file: security_summary.txt
            summary_format: "Security Issues Found: {score}"
          - job: lint
            needs_env: false
            make_target: ci-lint
            summary_script: extract_lint_score.py
            summary_file: lint_summary.txt
            summary_format: "Lint Score: {score}/10"
      fail-fast: false
    
    name: ${{ matrix.job }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Configure environment
        if: matrix.needs_env
        env:
          SECRET_VARS: ${{ secrets.ENV_VARS }}
        run: |
          echo "$SECRET_VARS" | jq -r 'to_entries[] | "\(.key)=\(.value)"' >> $GITHUB_ENV
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        working-directory: ${{ env.WORKING_DIR }}
        run: make install-all
          
      - name: Run ${{ matrix.job }} check
        working-directory: ${{ env.WORKING_DIR }}
        run: make ${{ matrix.make_target }}
          
      - name: Upload to Codecov
        if: matrix.job == 'coverage' || matrix.job == 'test'
        uses: codecov/codecov-action@v3
        with:
          file: ./backend/reports/coverage.json
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          
      - name: Generate summary
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          if [ -f "reports/${matrix.job}_report.json" ]; then
            SCORE=$(python ${{ matrix.summary_script }} reports/${matrix.job}_report.json)
            echo "${{ matrix.summary_format }}".format(score="$SCORE")
            echo "${{ matrix.summary_format }}".format(score="$SCORE") > ${{ matrix.summary_file }}
          else
            echo "${{ matrix.summary_format }}".format(score="0 (no report generated)")
            echo "${{ matrix.summary_format }}".format(score="0") > ${{ matrix.summary_file }}
          fi
          
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ${{ matrix.job }}-report
          path: |
            ${{ env.WORKING_DIR }}/reports/
            ${{ env.WORKING_DIR }}/.pytest_cache/
            ${{ env.WORKING_DIR }}/pytest.log
            ${{ env.WORKING_DIR }}/${{ matrix.summary_file }}
          retention-days: 30
          
      - name: Upload summary
        uses: actions/upload-artifact@v4
        if: always() && matrix.job != 'test'
        with:
          name: ${{ matrix.job }}-summary
          path: ${{ env.WORKING_DIR }}/${{ matrix.summary_file }}
          retention-days: 7

  # Generate comprehensive quality report
  quality-summary:
    runs-on: ubuntu-latest
    name: Quality Summary
    needs: quality-check
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Create comprehensive quality report
        run: |
          # Create report header
          cat > comprehensive_report.md << 'EOF'
          # TravelStyle AI Backend - Code Quality Report
          
          Generated on: $(date)
          
          ## 🧪 Test Results
          EOF
          
          # Add test results
          if [ -d "artifacts/test-report" ]; then
            echo "✅ Tests completed - see pytest artifacts for details" >> comprehensive_report.md
          else
            echo "❌ Tests failed or not found" >> comprehensive_report.md
          fi
          echo "" >> comprehensive_report.md
          
          # Add coverage info
          echo "## 📊 Coverage Report" >> comprehensive_report.md
          if [ -f "artifacts/coverage-summary/coverage_summary.txt" ]; then
            cat artifacts/coverage-summary/coverage_summary.txt >> comprehensive_report.md
          else
            echo "❌ Coverage report not available" >> comprehensive_report.md
          fi
          echo "" >> comprehensive_report.md
          
          # Add security info
          echo "## 🔒 Security Scan" >> comprehensive_report.md
          if [ -f "artifacts/security-summary/security_summary.txt" ]; then
            cat artifacts/security-summary/security_summary.txt >> comprehensive_report.md
          else
            echo "❌ Security scan not available" >> comprehensive_report.md
          fi
          echo "" >> comprehensive_report.md
          
          # Add lint info
          echo "## 🔍 Code Quality (Pylint)" >> comprehensive_report.md
          if [ -f "artifacts/lint-summary/lint_summary.txt" ]; then
            cat artifacts/lint-summary/lint_summary.txt >> comprehensive_report.md
          else
            echo "❌ Lint report not available" >> comprehensive_report.md
          fi
          echo "" >> comprehensive_report.md
          
          # Add artifacts section
          cat >> comprehensive_report.md << 'EOF'
          ## 📁 Available Artifacts
          - **test-report**: Test execution logs, results, and coverage data
          - **coverage-report**: Same as test-report (coverage included in tests)
          - **security-report**: Security scan results (JSON + HTML)
          - **lint-report**: Code quality reports (JSON + HTML)
          - **quality-summary**: This comprehensive report
          
          ## 🎯 Quick Links
          - [View Coverage Report](../artifacts/test-report/reports/htmlcov/index.html)
          - [View Security Report](../artifacts/security-report/reports/bandit_report.html)
          - [View Pylint Report](../artifacts/lint-report/reports/pylint_report.html)
          
          ---
          *Report generated by TravelStyle AI Backend CI/CD Pipeline*
          EOF
          
          echo "📋 Generated Quality Report:"
          cat comprehensive_report.md
          
      - name: Upload comprehensive report
        uses: actions/upload-artifact@v4
        with:
          name: quality-summary
          path: comprehensive_report.md
          retention-days: 30
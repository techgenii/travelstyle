name: Backend Quality CI/CD

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'backend/**'
      - '.github/workflows/ci.yml'

# https://docs.github.com/en/actions/using-jobs/assigning-permissions-to-jobs
# `contents` is for permission to the contents of the repository.
# `pull-requests` is for permission to pull request
permissions:
  contents: write
  checks: write
  pull-requests: write

env:
  PYTHON_VERSION: '3.13'
  WORKING_DIR: backend

jobs:
  # Combined quality checks with improved test configuration
  quality-checks:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('backend/**/requirements*.txt') }}
          restore-keys: ${{ runner.os }}-pip-

      # Install dependencies
      - name: Install dependencies
        working-directory: ${{ env.WORKING_DIR }}
        run: |
          make install
          make install-dev

      # Run lint (produces XML)
      - name: Run lint
        working-directory: ${{ env.WORKING_DIR }}
        run: make prod-lint
        continue-on-error: true

      # Run security scan (produces JSON, convert to XML summary)
      - name: Run security scan
        working-directory: ${{ env.WORKING_DIR }}
        run: make prod-security
        continue-on-error: true

      # Method 3: Most secure approach with validation
      - name: Validate and mask secrets
        run: |
          # Validate secrets exist
          if [[ -z "$OPENAI_API_KEY" || -z "$QLOO_API_KEY" ]]; then
            echo "❌ Required secrets are missing"
            exit 1
          fi

          # Mask secrets
          echo "::add-mask::$OPENAI_API_KEY"
          echo "::add-mask::$OPENAI_ORG_ID"
          echo "::add-mask::$QLOO_API_KEY"
          echo "::add-mask::$OPENWEATHER_API_KEY"
          echo "::add-mask::$EXCHANGE_API_KEY"
          echo "::add-mask::$SUPABASE_URL"
          echo "::add-mask::$SUPABASE_KEY"
          echo "✅ Secrets validated and masked"
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_ORG_ID: ${{ secrets.OPENAI_ORG_ID }}
          QLOO_API_KEY: ${{ secrets.QLOO_API_KEY }}
          OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
          EXCHANGE_API_KEY: ${{ secrets.EXCHANGE_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}

      # Run tests with improved configuration (warnings disabled)
      - name: Run tests with clean output
        working-directory: ${{ env.WORKING_DIR }}
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_ORG_ID: ${{ secrets.OPENAI_ORG_ID }}
          QLOO_API_KEY: ${{ secrets.QLOO_API_KEY }}
          OPENWEATHER_API_KEY: ${{ secrets.OPENWEATHER_API_KEY }}
          EXCHANGE_API_KEY: ${{ secrets.EXCHANGE_API_KEY }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: |
          echo "🚀 Running tests with improved configuration (warnings disabled)"
          make prod-test

      # Upload coverage reports to Codecov
      - name: Upload coverage reports to Codecov
        uses: codecov/codecov-action@v5
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
        with:
          fail_ci_if_error: false # optional (default = false)
          directory: ./${{ env.WORKING_DIR }}/reports
          files: ./pytest-coverage.xml, ./pytest-results.xml
          verbose: true # optional (default = false)

      # Upload all XML artifacts
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-reports
          path: |
            ${{ env.WORKING_DIR }}/reports/ruff_junit.xml
            ${{ env.WORKING_DIR }}/reports/bandit_report.json
            ${{ env.WORKING_DIR }}/reports/pytest-results.xml
            ${{ env.WORKING_DIR }}/reports/pytest-coverage.json
            ${{ env.WORKING_DIR }}/reports/pytest-coverage.xml
            ${{ env.WORKING_DIR }}/reports/pytest-coverage.txt
          retention-days: 30

  # Generate badges from XML artifacts
  update-badges:
    runs-on: ubuntu-latest
    needs: [quality-checks]
    if: always()
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      - uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Extract scores and update badges
        run: |
          # Extract lint score from ruff XML
          LINT_ISSUES=$(xmllint --xpath "count(//testcase[@classname='ruff']/failure)" artifacts/quality-reports/ruff_junit.xml 2>/dev/null || echo "0")
          # Extract security issues from bandit JSON
          SECURITY_ISSUES=$(python3 -c "
          import json
          try:
              with open('artifacts/quality-reports/bandit_report.json', 'r') as f:
                  data = json.load(f)
                  print(len(data.get('results', [])))
          except:
              print('0')
          " 2>/dev/null || echo "0")
          # Extract coverage from coverage JSON
          COVERAGE=$(python3 -c "
          import json
          try:
              with open('artifacts/quality-reports/pytest-coverage.json', 'r') as f:
                  data = json.load(f)
                  print(int(data.get('totals', {}).get('percent_covered', 0)))
          except:
              print('0')
          " 2>/dev/null || echo "0")
          # Extract test results from XML
          TEST_FAILURES=$(xmllint --xpath "count(//testcase/failure)" artifacts/quality-reports/pytest-results.xml 2>/dev/null || echo "0")
          TEST_ERRORS=$(xmllint --xpath "count(//testcase/error)" artifacts/quality-reports/pytest-results.xml 2>/dev/null || echo "0")
          TOTAL_TESTS=$(xmllint --xpath "count(//testcase)" artifacts/quality-reports/pytest-results.xml 2>/dev/null || echo "0")
          # Calculate badge colors
          if [ "$LINT_ISSUES" -eq 0 ]; then
            LINT_COLOR="brightgreen"
          elif [ "$LINT_ISSUES" -le 5 ]; then
            LINT_COLOR="orange"
          else
            LINT_COLOR="red"
          fi
          if [ "$SECURITY_ISSUES" -eq 0 ]; then
            SEC_COLOR="brightgreen"
          elif [ "$SECURITY_ISSUES" -le 2 ]; then
            SEC_COLOR="orange"
          else
            SEC_COLOR="red"
          fi
          if [ "$COVERAGE" -ge 80 ]; then
            COV_COLOR="brightgreen"
          elif [ "$COVERAGE" -ge 60 ]; then
            COV_COLOR="orange"
          else
            COV_COLOR="red"
          fi
          if [ "$TEST_FAILURES" -eq 0 ] && [ "$TEST_ERRORS" -eq 0 ]; then
            TEST_COLOR="brightgreen"
          else
            TEST_COLOR="red"
          fi
          # Create or update README badges (excluding Codecov badge)
          if [ -f "README.md" ]; then
            # Update existing badges or add new ones
            sed -i "s|https://img.shields.io/badge/ruff-[^)]*|https://img.shields.io/badge/ruff-${LINT_ISSUES}%20issues-${LINT_COLOR}|g" README.md
            sed -i "s|https://img.shields.io/badge/bandit-[^)]*|https://img.shields.io/badge/bandit-${SECURITY_ISSUES}%20issues-${SEC_COLOR}|g" README.md
            sed -i "s|https://img.shields.io/badge/tests-[^)]*|https://img.shields.io/badge/tests-${TOTAL_TESTS}%20passed-${TEST_COLOR}|g" README.md
            # If badges don't exist, add them to the top of README
            if ! grep -q "img.shields.io/badge/ruff" README.md; then
              sed -i '1i\
              ![Ruff](https://img.shields.io/badge/ruff-'${LINT_ISSUES}'%20issues-'${LINT_COLOR}') \
              ![Bandit](https://img.shields.io/badge/bandit-'${SECURITY_ISSUES}'%20issues-'${SEC_COLOR}') \
              ![Tests](https://img.shields.io/badge/tests-'${TOTAL_TESTS}'%20passed-'${TEST_COLOR}')\
              ' README.md
            fi
          fi
          # Create summary report
          cat > quality_summary.md << EOF
          # Quality Report - $(date)
          ## 📊 Metrics
          - **Lint Issues**: ${LINT_ISSUES}
          - **Security Issues**: ${SECURITY_ISSUES}
          - **Test Coverage**: ${COVERAGE}%
          - **Tests**: ${TOTAL_TESTS} total, ${TEST_FAILURES} failures, ${TEST_ERRORS} errors
          ## 🎯 Status
          - Lint: $([ "$LINT_ISSUES" -eq 0 ] && echo "✅ PASS" || echo "❌ ISSUES FOUND")
          - Security: $([ "$SECURITY_ISSUES" -eq 0 ] && echo "✅ PASS" || echo "❌ ISSUES FOUND")
          - Coverage: $([ "$COVERAGE" -ge 80 ] && echo "✅ PASS" || echo "❌ BELOW THRESHOLD")
          - Tests: $([ "$TEST_FAILURES" -eq 0 ] && [ "$TEST_ERRORS" -eq 0 ] && echo "✅ PASS" || echo "❌ FAILURES")
          ## 🚀 Improvements
          - ✅ Tests run with warnings disabled for cleaner output
          - ✅ Improved test organization with specific test suites
          - ✅ Better error handling and reporting
          EOF
          echo "Quality Summary:"
          cat quality_summary.md
      - uses: actions/upload-artifact@v4
        with:
          name: quality-summary
          path: quality_summary.md
          retention-days: 30

      - name: Commit badge updates
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add README.md
          if ! git diff --staged --quiet; then
            git commit -m "Update quality badges [skip ci]"
            git push
          else
            echo "No changes to README.md, skipping commit"
          fi

  # Generate test coverage from XML artifacts
  update-coverage-on-readme:
    runs-on: ubuntu-latest
    needs: [update-badges]
    if: always()
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Pytest coverage comment
        id: coverageComment
        uses: MishaKav/pytest-coverage-comment@main
        with:
          pytest-coverage-path: artifacts/quality-reports/pytest-coverage.txt
          title: Code Coverage Report
          junitxml-path: artifacts/quality-reports/pytest-results.xml
          junitxml-title: Code Test Results Report

      - name: Update Readme with Coverage Html
        if: ${{ github.ref == 'refs/heads/main' }}
        run: |
          echo "🔄 Updating README.md with coverage data..."
          echo "Coverage HTML: ${{ steps.coverageComment.outputs.coverageHtml }}"

          echo "📝 Before update:"
          grep -A 5 -B 1 "<!-- Pytest Coverage Comment:" ./README.md || echo "No markers found"

          sed -i '/<!-- Pytest Coverage Comment:Begin -->/,/<!-- Pytest Coverage Comment:End -->/c\<!-- Pytest Coverage Comment:Begin -->\n\${{ steps.coverageComment.outputs.coverageHtml }}\n<!-- Pytest Coverage Comment:End -->' ./README.md

          echo "✅ After update:"
          grep -A 5 -B 1 "<!-- Pytest Coverage Comment:" ./README.md
          echo "🎉 README.md updated successfully!"

      - name: Commit & Push changes to Readme
        if: ${{ github.ref == 'refs/heads/main' }}
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          # Fetch latest changes and reset to origin/main
          git fetch origin main
          git reset --hard origin/main
          git add README.md
          if ! git diff --staged --quiet; then
            git commit -m "Update coverage on Readme"
            git push origin main
          else
            echo "No changes to README.md, skipping commit"
          fi
